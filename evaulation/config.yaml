# --- Model Configuration ---
# Model used to generate the answer from the retrieved context
generation_model_name: "gemini-2.5-flash"  # Faster and cheaper for generation
# Model used to perform the multi-faceted evaluation
evaluation_model_name: "gemini-2.5-pro" # Keep pro for accurate evaluation

ranker_model_name: "gemini-2.5-flash-lite"  # Faster and cheaper for ranking

# --- File Paths ---
golden_dataset_path: "golden_dataset.jsonl"
output_folder: "evaluation_reports"
cache_path: "cache_reranked2.json" # Use a new cache file for the reranked run
cache_path_without_rank: "cache2.json"

# --- Evaluation Parameters ---
top_k: 3
# The number of top context chunks to use for generating the answer
num_context_chunks: 2
# The delay in seconds between processing each item to respect API rate limits
rate_limit_delay: 3  # Reduced from 8 to 3 seconds - much faster evaluation